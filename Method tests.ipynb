{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests for different classes #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for methods of the Layer classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.,  1., -1.],\n",
      "        [ 1., -1.,  1.],\n",
      "        [-1.,  1., -1.],\n",
      "        [ 1., -1.,  1.]], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from Layers.Layers import MSALinearLayer, ReluLayer\n",
    "from Networks.ResNet import ConvNet, FCNet\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "layer = MSALinearLayer(in_features=3, out_features=4, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.,  2., -2.,  2.], dtype=torch.float64, grad_fn=<SqueezeBackward3>)\n",
      "tensor([-2.,  2., -2.,  2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def forward_test():\n",
    "    x = torch.tensor([1,2,3], dtype=torch.float64)\n",
    "    res = layer.forward(x)\n",
    "    print(res)\n",
    "    goal = torch.tensor([-2,2,-2,2], dtype=torch.float64)\n",
    "    print(goal)\n",
    "    \n",
    "forward_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4., dtype=torch.float64, grad_fn=<DotBackward>)\n",
      "4\n",
      "tensor([ 2., -2.,  2.], dtype=torch.float64)\n",
      "[2, -2, 2]\n"
     ]
    }
   ],
   "source": [
    "def hamilton_test():\n",
    "    x = torch.tensor([1,2,3], dtype=torch.float64, requires_grad=True)\n",
    "    lambd = torch.tensor([1,2,3,4], dtype=torch.float64)\n",
    "    res = layer.hamilton(x,lambd)\n",
    "    print(res)\n",
    "    goal = 4\n",
    "    print(goal)\n",
    "    res.backward()\n",
    "    print(x.grad)\n",
    "    goal = [2, -2, 2]\n",
    "    print(goal)\n",
    "hamilton_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_batch0FC1': tensor([1., 2., 3.], dtype=torch.float64), 'x_batch1FC1': tensor([2., 3., 0.], dtype=torch.float64)}\n",
      "{'lambda_batch0FC2': tensor([1., 2., 3., 4.], dtype=torch.float64), 'lambda_batch1FC2': tensor([4., 1., 3., 2.], dtype=torch.float64)}\n",
      "tensor([[4.5000, 7.0000, 1.5000],\n",
      "        [2.0000, 3.5000, 3.0000],\n",
      "        [4.5000, 7.5000, 4.5000],\n",
      "        [4.0000, 7.0000, 6.0000]], dtype=torch.float64)\n",
      "tensor([[ 9, 14,  3],\n",
      "        [ 4,  7,  6],\n",
      "        [ 9, 15,  9],\n",
      "        [ 8, 14, 12]])\n",
      "Parameter containing:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "{'x_batch0FC1': tensor([1., 2., 3.], dtype=torch.float64), 'x_batch1FC1': tensor([2., 3., 0.], dtype=torch.float64)}\n",
      "{'lambda_batch0FC2': tensor([ 0., -2.,  1., -3.], dtype=torch.float64), 'lambda_batch1FC2': tensor([-1., -2.,  3., -4.], dtype=torch.float64)}\n",
      "tensor([[-1.0000, -1.5000,  0.0000],\n",
      "        [-3.0000, -5.0000, -3.0000],\n",
      "        [ 3.5000,  5.5000,  1.5000],\n",
      "        [-5.5000, -9.0000, -4.5000]], dtype=torch.float64)\n",
      "tensor(11)\n",
      "tensor([[ -2,  -3,   0],\n",
      "        [ -6, -10,  -6],\n",
      "        [  7,  11,   3],\n",
      "        [-11, -18,  -9]])\n",
      "Parameter containing:\n",
      "tensor([[-1., -1.,  1.],\n",
      "        [-1., -1., -1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [-1., -1., -1.]], dtype=torch.float64, requires_grad=True)\n",
      "tensor([[-1, -1,  1],\n",
      "        [-1, -1, -1],\n",
      "        [ 1,  1,  1],\n",
      "        [-1, -1, -1]])\n"
     ]
    }
   ],
   "source": [
    "def gen_dict(name, elements, layer_index):\n",
    "    res_dict = {}\n",
    "    for i in range(len(elements)):\n",
    "        dict_key = name+'_batch'+str(i)+'FC'+str(layer_index)\n",
    "        res_dict.update({dict_key:torch.tensor(elements[i], dtype=torch.float64)})\n",
    "    return res_dict\n",
    "    \n",
    "\n",
    "def set_weights_test_1():\n",
    "    layer_index = 1\n",
    "    batch_size = 2\n",
    "    x_dict = gen_dict('x', [[1,2,3],[2,3,0]], layer_index)\n",
    "    lambda_dict = gen_dict('lambda', [[1,2,3,4],[4,1,3,2]], layer_index+1)\n",
    "    layer.set_weights(layer_index, x_dict, lambda_dict, batch_size)\n",
    "    goal_m = torch.tensor([[9,14,3],[4,7,6],[9,15,9],[8,14,12]])\n",
    "    print(goal_m)\n",
    "    print(layer.linear.weight)\n",
    "    goal = torch.tensor([[1,1,1],[1,1,1],[1,1,1],[1,1,1]])\n",
    "    print(goal)\n",
    "    \n",
    "    \n",
    "\n",
    "def set_weights_test_2():\n",
    "    layer_index = 1\n",
    "    batch_size = 2\n",
    "    x_dict = gen_dict('x', [[1,2,3],[2,3,0]], layer_index)\n",
    "    lambda_dict = gen_dict('lambda', [[0,-2,1,-3],[-1,-2,3,-4]], layer_index+1)\n",
    "    layer.set_weights(layer_index, x_dict, lambda_dict, batch_size)\n",
    "    goal_m = torch.tensor([[-2,-3,0],[-6,-10,-6],[7,11,3],[-11,-18,-9]])\n",
    "    print(torch.max(goal_m))\n",
    "    print(goal_m)\n",
    "    print(layer.linear.weight)\n",
    "    goal = torch.tensor([[-1,-1,1],[-1,-1,-1],[1,1,1],[-1,-1,-1]])\n",
    "    print(goal)\n",
    "    \n",
    "set_weights_test_1()\n",
    "\n",
    "set_weights_test_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests for methods of the ConvNet classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.,  1., -1.],\n",
      "        [ 1., -1.,  1.],\n",
      "        [-1.,  1., -1.],\n",
      "        [ 1., -1.,  1.]], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.,  1., -1.,  1.],\n",
      "        [ 1., -1.,  1., -1.]], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "net = FCNet(num_fc=2,sizes_fc=[3,4,2], test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pscha\\Documents\\GitHub\\OC-Methods-for-DL\\Networks\\ResNet.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.x_dict.update({x_key:torch.tensor(x, requires_grad=True)})\n",
      "C:\\Users\\pscha\\Documents\\GitHub\\OC-Methods-for-DL\\Networks\\ResNet.py:342: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.x_dict.update({x_key:torch.tensor(x, requires_grad=True)})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_batch1FC0': tensor([1., 2., 3.], dtype=torch.float64, requires_grad=True), 'x_batch1FC1': tensor([-2.,  2., -2.,  2.], dtype=torch.float64, requires_grad=True), 'x_batch1FC2': tensor([0., 2., 0., 2.], dtype=torch.float64, requires_grad=True), 'x_batch1FC3': tensor([ 4., -4.], dtype=torch.float64, requires_grad=True)}\n"
     ]
    }
   ],
   "source": [
    "def forward_test():\n",
    "    x_test = torch.tensor([1,2,3], dtype=torch.float64)\n",
    "    net.batch_element = 1\n",
    "    net.forward(x_test)\n",
    "    print(net.x_dict)\n",
    "    \n",
    "forward_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pscha\\Documents\\GitHub\\OC-Methods-for-DL\\Networks\\ResNet.py:339: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.x_dict.update({x_key:torch.tensor(x, requires_grad=True)})\n",
      "C:\\Users\\pscha\\Documents\\GitHub\\OC-Methods-for-DL\\Networks\\ResNet.py:342: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.x_dict.update({x_key:torch.tensor(x, requires_grad=True)})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_batch1FC0': tensor([3., 1., 2.], dtype=torch.float64, requires_grad=True), 'x_batch1FC1': tensor([-4.,  4., -4.,  4.], dtype=torch.float64, requires_grad=True), 'x_batch1FC2': tensor([0., 4., 0., 4.], dtype=torch.float64, requires_grad=True), 'x_batch1FC3': tensor([ 8., -8.], dtype=torch.float64, requires_grad=True), 'x_batch0FC0': tensor([1., 2., 3.], dtype=torch.float64, requires_grad=True), 'x_batch0FC1': tensor([-2.,  2., -2.,  2.], dtype=torch.float64, requires_grad=True), 'x_batch0FC2': tensor([0., 2., 0., 2.], dtype=torch.float64, requires_grad=True), 'x_batch0FC3': tensor([ 4., -4.], dtype=torch.float64, requires_grad=True)}\n",
      "{'lambda_batch0FC3': tensor([-0.9997,  0.9997], dtype=torch.float64), 'lambda_batch0FC2': tensor([ 1.9993, -1.9993,  1.9993, -1.9993], dtype=torch.float64), 'lambda_batch0FC1': tensor([ 0.0000, -1.9993,  0.0000, -1.9993], dtype=torch.float64), 'lambda_batch0FC0': tensor([-3.9987,  3.9987, -3.9987], dtype=torch.float64), 'lambda_batch1FC3': tensor([ 1.1254e-07, -1.1254e-07], dtype=torch.float64), 'lambda_batch1FC2': tensor([-2.2507e-07,  2.2507e-07, -2.2507e-07,  2.2507e-07],\n",
      "       dtype=torch.float64), 'lambda_batch1FC1': tensor([0.0000e+00, 2.2507e-07, 0.0000e+00, 2.2507e-07], dtype=torch.float64), 'lambda_batch1FC0': tensor([ 4.5014e-07, -4.5014e-07,  4.5014e-07], dtype=torch.float64)}\n",
      "tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.9997, -1.9993, -2.9990],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-0.9997, -1.9993, -2.9990]], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "{'x_batch1FC0': tensor([3., 1., 2.], dtype=torch.float64, requires_grad=True), 'x_batch1FC1': tensor([-4.,  4., -4.,  4.], dtype=torch.float64, requires_grad=True), 'x_batch1FC2': tensor([0., 4., 0., 4.], dtype=torch.float64, requires_grad=True), 'x_batch1FC3': tensor([ 8., -8.], dtype=torch.float64, requires_grad=True), 'x_batch0FC0': tensor([1., 2., 3.], dtype=torch.float64, requires_grad=True), 'x_batch0FC1': tensor([-2.,  2., -2.,  2.], dtype=torch.float64, requires_grad=True), 'x_batch0FC2': tensor([0., 2., 0., 2.], dtype=torch.float64, requires_grad=True), 'x_batch0FC3': tensor([ 4., -4.], dtype=torch.float64, requires_grad=True)}\n",
      "{'lambda_batch0FC3': tensor([-0.9997,  0.9997], dtype=torch.float64), 'lambda_batch0FC2': tensor([ 1.9993, -1.9993,  1.9993, -1.9993], dtype=torch.float64), 'lambda_batch0FC1': tensor([ 0.0000, -1.9993,  0.0000, -1.9993], dtype=torch.float64), 'lambda_batch0FC0': tensor([-3.9987,  3.9987, -3.9987], dtype=torch.float64), 'lambda_batch1FC3': tensor([ 1.1254e-07, -1.1254e-07], dtype=torch.float64), 'lambda_batch1FC2': tensor([-2.2507e-07,  2.2507e-07, -2.2507e-07,  2.2507e-07],\n",
      "       dtype=torch.float64), 'lambda_batch1FC1': tensor([0.0000e+00, 2.2507e-07, 0.0000e+00, 2.2507e-07], dtype=torch.float64), 'lambda_batch1FC0': tensor([ 4.5014e-07, -4.5014e-07,  4.5014e-07], dtype=torch.float64)}\n",
      "tensor([[ 0.0000, -0.9997,  0.0000, -0.9997],\n",
      "        [ 0.0000,  0.9997,  0.0000,  0.9997]], dtype=torch.float64,\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([12., 12.], dtype=torch.float64, grad_fn=<SqueezeBackward3>)\n",
      "tensor([12., 12.], dtype=torch.float64, grad_fn=<SqueezeBackward3>)\n"
     ]
    }
   ],
   "source": [
    "def single_iteration_test():\n",
    "    x_test_1 = torch.tensor([1,2,3], dtype=torch.float64)\n",
    "    label_test_1 = torch.tensor([1,0])\n",
    "    x_test_2 = torch.tensor([3,1,2], dtype=torch.float64)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    net.batch_element = 0\n",
    "    net.msa_step_1(x_test_1)\n",
    "    net.msa_step_2(criterion, label_test_1)\n",
    "    net.batch_element = 1\n",
    "    net.msa_step_1(x_test_2)\n",
    "    net.msa_step_2(criterion, label_test_1)\n",
    "    net.msa_step_3(2)\n",
    "    print(net.forward(x_test_1))\n",
    "    print(net.forward(x_test_2))\n",
    "single_iteration_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0],\n",
      "        [0, 4]])\n"
     ]
    }
   ],
   "source": [
    "x= torch.tensor([[1,2],[3,4]])\n",
    "y= torch.tensor([[1,0],[0,1]])\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0003, dtype=torch.float64, grad_fn=<NllLossBackward>)\n",
      "tensor([[ 0.9997, -0.9997]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "x_res = torch.tensor([[4,-4]], dtype=torch.float64, requires_grad=True)\n",
    "x_label = torch.tensor([1])\n",
    "loss = criterion(x_res,x_label)\n",
    "print(loss)\n",
    "loss.backward()\n",
    "print(x_res.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 2., 0.], dtype=torch.float64, grad_fn=<ReluBackward0>)\n",
      "tensor(4., dtype=torch.float64, grad_fn=<DotBackward>)\n",
      "tensor([0., 2., 0.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x_test = torch.tensor([-1,2,-3], dtype=torch.float64, requires_grad=True)\n",
    "p_test = torch.tensor([1,2,3], dtype=torch.float64)\n",
    "x_neu = F.relu(x_test)\n",
    "print(x_neu)\n",
    "H=torch.dot(x_neu,p_test)\n",
    "print(H)\n",
    "H.backward()\n",
    "print(x_test.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
