{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import timeit\n",
    "\n",
    "class MNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.len = len(self.data['label'].values)\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "            \n",
    "        self.features = torch.tensor(self.data.drop('label',axis=1).values.astype(np.float32), device=self.device).reshape(-1,1,28,28)/255\n",
    "        self.labels = self.one_hot(self.data['label'].values,10)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "    \n",
    "    def one_hot(self, labels, num_classes):\n",
    "        result = torch.zeros([len(labels), num_classes], dtype=torch.float32, device=self.device)\n",
    "        for index, label in enumerate(labels):\n",
    "            result[index][label]=1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "63bf75242268bbc9600ef92efd90bdec09e9ab71"
   },
   "outputs": [],
   "source": [
    "train = MNISTDataset('../input/mnist_train.csv')\n",
    "train_loader = torch.utils.data.DataLoader(train)\n",
    "\n",
    "test = MNISTDataset('../input/mnist_test.csv')\n",
    "test_loader = torch.utils.data.DataLoader(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fccfcb434228b71e106e58ff12466306e814ff09"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    '''ResNet class with variable size, specified in the constructor'''\n",
    "    def __init__(self, num_conv, subs_points, num_kernels, num_fc=1, sizes_fc=[1000], res_skips=1):#, subs_style='conv'\n",
    "        super(ResNet, self).__init__()\n",
    "        self.num_conv = num_conv\n",
    "        self.num_fc = num_fc\n",
    "        self.subs_points = subs_points\n",
    "        self.res_skips = res_skips\n",
    "        \n",
    "        self.conv_keys = ['Conv'+str(i) for i in range(num_conv)]\n",
    "        self.fc_keys = ['FC'+str(i) for i in range(num_fc)]\n",
    "        self.subs_keys = ['Conv1x1'+str(i) for i in range(len(subs_points))]\n",
    "        \n",
    "        self._init_conv_layers(num_kernels)\n",
    "        num_pix = num_kernels[-1] * 784 / (4**len(subs_points))\n",
    "        self._init_fc_layers(sizes_fc, num_pix)\n",
    "        self._init_conv_subs_layers(num_kernels)\n",
    "        #keys = ['Conv'+str(i) for i in range(self.num_conv)]\n",
    "            \n",
    "        \n",
    "    def _init_conv_layers(self, num_kernels):\n",
    "        #keys = ['Conv'+str(i) for i in range(self.num_conv)]\n",
    "        num_kernel_counter = 0\n",
    "        current_key = 0\n",
    "        channels = 1\n",
    "        for i in range(self.num_conv):\n",
    "            if i in self.subs_points:\n",
    "                num_kernel_counter += 1\n",
    "                setattr(self, self.conv_keys[current_key], nn.Conv2d(channels, num_kernels[num_kernel_counter], 3, stride=2, padding=1))\n",
    "                channels = num_kernels[num_kernel_counter]\n",
    "                current_key += 1\n",
    "            else:\n",
    "                setattr(self, self.conv_keys[current_key], nn.Conv2d(channels, num_kernels[num_kernel_counter], 3, padding=1))\n",
    "                channels = num_kernels[num_kernel_counter]\n",
    "                current_key += 1\n",
    "                \n",
    "    def _init_fc_layers(self, sizes_fc, num_pix):\n",
    "        #keys = ['FC'+str(i) for i in range(num_fc)]\n",
    "        sizes = [num_pix]+sizes_fc\n",
    "        for i in range(self.num_fc):\n",
    "            setattr(self, self.fc_keys[i], nn.Linear(int(sizes[i]), int(sizes[i+1])))\n",
    "            #print(sizes[i], sizes[i+1])\n",
    "            \n",
    "            \n",
    "    def _init_conv_subs_layers(self, num_kernels):\n",
    "        '''subsampling of identity via 1x1 convolution'''\n",
    "        #channels = [1] + num_kernels\n",
    "        for layer in range(len(self.subs_points)):\n",
    "            setattr(self, self.subs_keys[layer], nn.Conv2d(num_kernels[layer], num_kernels[layer+1], 1, stride=2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''single res_skip, x_neu = x+Relu(W*x)'''\n",
    "        #print(x.size())\n",
    "        for layer in range(self.num_conv):\n",
    "            if layer in self.subs_points:\n",
    "                x = self.subsample(x, self.subs_points.index(layer)) + F.relu(getattr(self, self.conv_keys[layer])(x))\n",
    "                #print(x.size())\n",
    "            else:\n",
    "                x = x + F.relu(getattr(self, self.conv_keys[layer])(x))\n",
    "                #print(x.size())\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        #print(x.size())\n",
    "        for layer in range(self.num_fc-1):\n",
    "            x = F.relu(getattr(self, self.fc_keys[layer])(x))\n",
    "            #print(x.size())\n",
    "        x = F.softmax(getattr(self, self.fc_keys[self.num_fc-1])(x), dim=1)      \n",
    "        #print(x.size())\n",
    "        return x\n",
    "    \n",
    "    def subsample(self, x, index):\n",
    "        x = getattr(self, self.subs_keys[index])(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    def train_backprop(self, num_epochs, dataloader, output_frequency=1000):\n",
    "        tic=timeit.default_timer()\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "        loss_sum = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            for index, (data, target) in enumerate(dataloader):\n",
    "                output = net(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss_sum = loss_sum + loss.data\n",
    "                if index % (10*(output_frequency)) == 0:\n",
    "                    print(\"#  Epoch  #  Batch  #  Avg-Loss ###############\")\n",
    "                if index % (output_frequency) == 0 and index > 0:\n",
    "                    print(\"#  %d  #  %d  #  %f  #\" % (epoch+1, index, loss_sum/output_frequency))\n",
    "                    loss_sum = 0\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        toc=timeit.default_timer()\n",
    "        print('Time elapsed: ',toc-tic)\n",
    "        \n",
    "    def test(self, dataloader, test_set_size):\n",
    "        with torch.no_grad():\n",
    "            correct_pred = 0\n",
    "            for index, (data, label) in enumerate(dataloader):\n",
    "                prediction = self.forward(data)\n",
    "                val, ind = torch.max(prediction,1)\n",
    "                val_label, ind_label = torch.max(label, 1)\n",
    "                if ind_label == ind:\n",
    "                    correct_pred += 1\n",
    "            print('Test set accuracy: ', correct_pred/test_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c2bc3c2c5e18b10dc3e2d7d7cdad31134168324"
   },
   "outputs": [],
   "source": [
    "net = ResNet(3,[1],[3,6],num_fc=2,sizes_fc=[100,10])\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cbdc6f73b5bf8d561ef464db90f4382369ba70e3"
   },
   "outputs": [],
   "source": [
    "net.train_backprop(1,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9477d3aff771eefc570d80add96c0e9071832401"
   },
   "outputs": [],
   "source": [
    "#net = ResNet(12,[1,5],[8,16,32],num_fc=3,sizes_fc=[1000,100,10])\n",
    "#print(net)\n",
    "#print(net.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b09dc49449a940a9c2eab379bdb7dd49b11fef25"
   },
   "outputs": [],
   "source": [
    "for index, (data,target) in enumerate(train_loader):\n",
    "    if index == 5:\n",
    "        print(net(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "90ee202f74c1ea40c7436de6b34d7c3fd43a8d42"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "tic=timeit.default_timer()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "num_epochs = 1\n",
    "#print(train.labels.is_cuda)\n",
    "for epoch in range(num_epochs):\n",
    "    for index, (data, target) in enumerate(train_loader):\n",
    "        #print(data)\n",
    "        output = net(data)\n",
    "        #print(target)\n",
    "        #print(output)\n",
    "        #print(target.is_cuda)\n",
    "        loss = criterion(output, target)\n",
    "        #print(loss.data)\n",
    "        if index % 1000 == 0:\n",
    "            print(epoch, index, loss.data)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "toc=timeit.default_timer()\n",
    "print('Time elapsed: ',toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c3a4caef55c9e835d267ff2d2efd0ee238f44df"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct_pred = 0\n",
    "    for index, (data, label) in enumerate(test_loader):\n",
    "        prediction = net(data)\n",
    "        val, ind = torch.max(prediction,1)\n",
    "        val_label, ind_label = torch.max(label, 1)\n",
    "        if ind_label == ind:\n",
    "            correct_pred += 1\n",
    "    print('Test set accuracy: ', correct_pred/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa42652f508f88b7ed26ffbe69e4b63d647ac173"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    '''Special test ResNet '''\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
